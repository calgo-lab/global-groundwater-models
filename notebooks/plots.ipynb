{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels\n",
    "#!pip install seaborn\n",
    "#!pip install tqmd\n",
    "#!pip install geopandas\n",
    "#!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T21:29:06.595028Z",
     "start_time": "2023-04-10T21:29:05.553007Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T21:29:09.699612Z",
     "start_time": "2023-04-10T21:29:09.677623Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FONT_SIZE = 16\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rc('font', size=FONT_SIZE)\n",
    "plt.rc('axes', titlesize=FONT_SIZE)\n",
    "plt.rc('axes', labelsize=FONT_SIZE)\n",
    "plt.rc('xtick', labelsize=14)\n",
    "plt.rc('ytick', labelsize=14)\n",
    "plt.rc('legend', fontsize=FONT_SIZE)\n",
    "plt.rc(\"savefig\", bbox='tight')\n",
    "plt.rc(\"savefig\", dpi=300) \n",
    "sns.set(rc=\n",
    "    {\"font.size\": FONT_SIZE,\n",
    "     \"axes.titlesize\": FONT_SIZE,\n",
    "     \"axes.labelsize\": FONT_SIZE,\n",
    "     \"xtick.labelsize\": 14,\n",
    "     \"ytick.labelsize\": 14,\n",
    "     \"legend.fontsize\": FONT_SIZE,\n",
    "     \"legend.title_fontsize\": FONT_SIZE,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T21:36:45.425859Z",
     "start_time": "2023-04-10T21:36:45.403407Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_germany(ax, color='grey'):\n",
    "    if not os.path.exists('plz-1stellig.shp'):\n",
    "        r = requests.get('https://downloads.suche-postleitzahl.org/v2/public/plz-1stellig.shp.zip')\n",
    "        with open('plz-1stellig.shp.zip', 'wb') as fd:\n",
    "            fd.write(r.content)\n",
    "        with zipfile.ZipFile('plz-1stellig.shp.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('plz-1stellig.shp')\n",
    "            os.remove('plz-1stellig.shp.zip')\n",
    "    plz_shape_df = gpd.read_file('plz-1stellig.shp', dtype={'plz': str})\n",
    "    plz_shape_df.plot(ax=ax, color=color, alpha=1., edgecolor=\"face\", linewidth=0.4, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T21:31:22.943817Z",
     "start_time": "2023-04-10T21:31:12.023926Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/carl/projects/gwl_neu'\n",
    "DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
    "RESULTS_PATH = os.path.join(BASE_PATH, 'results')\n",
    "FIGURES_PATH = os.path.join(BASE_PATH, 'figures')\n",
    "\n",
    "static_df = pd.read_feather(os.path.join(DATA_PATH, 'static.feather'))\n",
    "gwl_df = pd.read_feather(os.path.join(DATA_PATH, 'temporal.feather')).set_index(['proj_id', 'time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 01: Introduction to Groundwater level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T21:38:52.112198Z",
     "start_time": "2023-04-10T21:38:44.044468Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_01, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "plot_germany(ax)\n",
    "\n",
    "agg_df = gwl_df[['gwl']].groupby(axis=0, level=0).count()\n",
    "agg_df = agg_df.merge(static_df.set_index('proj_id')[['lat', 'lon']], left_index=True, right_index=True)\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    agg_df, geometry=gpd.points_from_xy(agg_df['lon'], agg_df['lat']))\n",
    "gdf.plot(column='gwl', ax=ax, legend=True, cmap='YlGnBu', markersize=4, aspect=1.5)\n",
    "ax.set(\n",
    "    xlabel='longitude',\n",
    "    ylabel='latitude',\n",
    ")\n",
    "fig_01.savefig(os.path.join(FIGURES_PATH, 'fig01.pdf'), format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig. 02: Examples of groundwater level time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T22:27:59.701683Z",
     "start_time": "2023-04-10T22:27:48.146055Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wells = ['BY_10134', 'NI_9850360', 'NI_9610811', 'NW_40607033',\n",
    "#         'NW_60090108', 'ST_44390001', 'BB_31481932', 'HE_8018',\n",
    "#         'ST_44360881', 'ST_46350389', 'TH_5140000063', 'RP_2511120600']\n",
    "\n",
    "wells = ['BY_10134', 'NW_40607033', 'ST_44390001', 'ST_44360881']\n",
    "letters = 'abcd'\n",
    "\n",
    "fig_02, ax = plt.subplots(1, 4, figsize=(22, 4))\n",
    "plt.subplots_adjust(hspace=0.45)\n",
    "\n",
    "for j in range(4):\n",
    "    gwl_df[gwl_df.index.get_level_values('proj_id') == wells[j]]['gwl'].droplevel(0, axis=0).plot(title=f'({letters[j]}) well id: {wells[j]}', ax=ax[j])\n",
    "    ax[j].set(xlabel=\"date\")\n",
    "    if j == 0:\n",
    "        ax[j].set(ylabel=\"groundwater level [m (asl)]\")\n",
    "\n",
    "fig_02.align_labels()\n",
    "fig_02.savefig(os.path.join(FIGURES_PATH, 'fig02.pdf'), format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 03: spatial interpolation setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_proj_ids = [\n",
    "    'BB_33522338', 'BB_34402050', 'BB_34426100', 'BB_36441970',\n",
    "    'BB_39431451', 'BW_100-517-0', 'BW_100-813-7', 'BW_101-713-8',\n",
    "    'BW_101-812-0', 'BW_103-714-0', 'BW_103-763-0', 'BW_104-112-1',\n",
    "    'BW_107-309-4', 'BW_107-517-2', 'BW_107-666-2', 'BW_109-812-6',\n",
    "    'BW_110-116-6', 'BW_111-568-6', 'BW_111-813-7', 'BW_115-113-3',\n",
    "    'BW_115-114-5', 'BW_116-721-2', 'BW_119-765-9', 'BW_119-771-0',\n",
    "    'BW_119-813-3', 'BW_122-021-6', 'BW_125-257-2', 'BW_131-115-0',\n",
    "    'BW_132-721-5', 'BW_135-064-6', 'BW_135-769-9', 'BW_139-119-9',\n",
    "    'BW_145-771-8', 'BW_154-772-0', 'BW_156-770-6', 'BW_158-767-0',\n",
    "    'BW_160-768-0', 'BW_164-772-6', 'BW_170-772-3', 'BW_172-772-2',\n",
    "    'BW_177-772-5', 'BW_188-258-0', 'BW_193-769-2', 'BW_2010-813-1',\n",
    "    'BW_4-812-8', 'BW_59-568-8', 'BY_11148', 'BY_83614', 'BY_9182',\n",
    "    'HE_11738', 'HE_12447', 'HE_13622', 'HE_5754', 'HE_5798',\n",
    "    'HE_6336', 'HE_6615', 'HE_7095', 'HE_7945', 'HE_8106', 'HE_8126',\n",
    "    'HE_8999', 'HE_9534', 'HE_9595', 'HE_9620', 'HE_9692',\n",
    "    'NI_100000467', 'NI_100000644', 'NI_100000670', 'NI_100000730',\n",
    "    'NI_100000732', 'NI_100000914', 'NI_200000660', 'NI_200001410',\n",
    "    'NI_40501911', 'NI_40502371', 'NI_40507101', 'NI_40507140',\n",
    "    'NI_9700168', 'NI_9700201', 'NW_110320037', 'NW_129660334',\n",
    "    'NW_59620286', 'NW_60100205', 'NW_70195213', 'NW_70195316',\n",
    "    'NW_70276018', 'NW_80100247', 'NW_80301680', 'NW_91122405',\n",
    "    'NW_91130104', 'NW_91141102', 'NW_91167309', 'NW_91173607',\n",
    "    'SH_10L56010001', 'SN_49420761', 'SN_49430964', 'SN_53403678',\n",
    "    'SN_54403689', 'ST_31380006', 'ST_41300022'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = np.radians([lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    haver_formula = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    r = 6371\n",
    "    dist = 2 * r * np.arcsin(np.sqrt(haver_formula))\n",
    "    return pd.Series(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "TARGET_LON = 10.75\n",
    "TARGET_LAT = 50.5\n",
    "\n",
    "fig_03, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(18, 12))\n",
    "\n",
    "plot_germany(ax1)\n",
    "plot_germany(ax2)\n",
    "\n",
    "\n",
    "## local interpolation\n",
    "ellipse = Ellipse(xy=(TARGET_LON, TARGET_LAT), width=2.8, height=0.66*2.8, \n",
    "                        edgecolor='#922a59ff', fc='None', lw=2)\n",
    "circle1 = plt.Circle((TARGET_LON, TARGET_LAT), 1.4, color='#922a59ff', fill=False)\n",
    "ax1.add_patch(ellipse)\n",
    "_df = static_df[['lat', 'lon']].copy().reset_index()\n",
    "_df['target_lon'] = TARGET_LON\n",
    "_df['target_lat'] = TARGET_LAT\n",
    "_df['dist'] = haversine(_df['target_lon'], _df['target_lat'], _df['lon'], _df['lat'])\n",
    "_df = _df[_df['dist'] < 120]\n",
    "sample_weights = -_df['dist']\n",
    "sample_weights -= sample_weights.min() - 0.01\n",
    "sample1 = _df.sample(6, weights=sample_weights, replace=False, random_state=3)\n",
    "sample2 = _df.sample(6, weights=sample_weights, replace=False, random_state=20)\n",
    "gdf0 = gpd.GeoDataFrame(\n",
    "    sample1, geometry=gpd.points_from_xy(sample1['lon'], sample1['lat']))\n",
    "gdf1 = gpd.GeoDataFrame(\n",
    "    sample2, geometry=gpd.points_from_xy(sample2['lon'], sample2['lat']))\n",
    "gdf0.plot(color='orange', marker='s', markersize=30, ax=ax1, aspect=1.5)\n",
    "gdf1.plot(color='#6cebdbff', marker='s', markersize=30, ax=ax1, aspect=1.5)\n",
    "for lon, lat in sample1[['lon', 'lat']].values:\n",
    "    ax1.plot([TARGET_LON, lon], [TARGET_LAT, lat], color='orange', linestyle='dashed', linewidth=1.0)\n",
    "for lon, lat in sample2[['lon', 'lat']].values:\n",
    "    ax1.plot([TARGET_LON, lon], [TARGET_LAT, lat], color='#6cebdb99', linestyle='dashed', linewidth=1.0)\n",
    "ax1.plot(TARGET_LON, TARGET_LAT, marker='X', markersize=15, markerfacecolor='#922a59ff')\n",
    "ax1.set(ylabel='latitude', xlabel='longitude', title='(a) local interpolation')\n",
    "\n",
    "## global interpolation\n",
    "_df = static_df.set_index('proj_id').loc[ref_proj_ids, ['lat', 'lon']]\n",
    "gdf2 = gpd.GeoDataFrame(\n",
    "    _df, geometry=gpd.points_from_xy(_df['lon'], _df['lat']))\n",
    "for lon, lat in _df[['lon', 'lat']].values:\n",
    "    ax2.plot([TARGET_LON, lon], [TARGET_LAT, lat], color='#80c55f99', linestyle='dashed', linewidth=1.0)\n",
    "ax2.plot(TARGET_LON, TARGET_LAT, marker='X', markersize=15, markerfacecolor='#922a59ff')\n",
    "gdf2.plot(color='#80c55fff', markersize=30, ax=ax2, aspect=1.5)\n",
    "ax2.set(xlabel='longitude', title='(b) global interpolation')\n",
    "\n",
    "## legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='X', color='#FFFFFF00', label='target location', markerfacecolor='#922a59ff', markersize=10),\n",
    "    Line2D([0], [0], color='#922a59ff', lw=2, label='local lookup bound.'),\n",
    "    Line2D([0], [0], marker='s', color='#FFFFFF00', label='random local reference well (sampling a)', markerfacecolor='orange', markersize=10),\n",
    "    Line2D([0], [0], marker='s', color='#FFFFFF00', label='random local reference well (sampling b)', markerfacecolor='#6cebdbff', markersize=10),    \n",
    "    Line2D([0], [0], marker='o', color='#FFFFFF00', label='fixed global reference well', markerfacecolor='#80c55fff', markersize=10),\n",
    "]\n",
    "ax2.legend(handles=legend_elements, bbox_to_anchor=(1.88, 1.03), loc='upper right')\n",
    "fig_03.savefig(os.path.join(FIGURES_PATH, 'fig03.pdf'), format='pdf', dpi=300.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 04: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = ['nhits', 'tft', 'tft_local_interpolation', 'tft_global_interpolation']\n",
    "\n",
    "metrics = []\n",
    "for model_name in MODELS:\n",
    "    _df = pd.read_feather(os.path.join(RESULTS_PATH, 'metrics', f'{model_name}_metrics.feather'))\n",
    "    _df['model'] = model_name\n",
    "    metrics.append(_df)\n",
    "metrics_df = pd.concat(metrics).reset_index(drop=True)\n",
    "\n",
    "nhits_subset = metrics_df[(metrics_df['model'] == 'nhits') & (metrics_df['proj_id'].isin(metrics_df.loc[metrics_df['model'] == 'tft_global_interpolation', 'proj_id']))].copy()\n",
    "nhits_subset['model'] = 'nhits_subset'\n",
    "tft_subset = metrics_df[(metrics_df['model'] == 'tft') & (metrics_df['proj_id'].isin(metrics_df.loc[metrics_df['model'] == 'tft_global_interpolation', 'proj_id']))].copy()\n",
    "tft_subset['model'] = 'tft_subset'\n",
    "metrics_df = pd.concat([metrics_df, nhits_subset, tft_subset]).reset_index(drop=True)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lim = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as grid_spec\n",
    "from matplotlib import colormaps\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "p = palette = sns.color_palette(\"colorblind\")\n",
    "colors = [p[4], p[6], p[3], p[1], p[0], p[2]]\n",
    "\n",
    "HORIZON = 1\n",
    "models = ['nhits', 'nhits_subset', 'tft', 'tft_subset', 'tft_local_interpolation', 'tft_global_interpolation']\n",
    "\n",
    "fig_04, ax = plt.subplots(6, 4, figsize=(22, 5), sharey=True)\n",
    "\n",
    "for j, (metric, _range) in enumerate([('NSE', (-1,1)), ('nRMSE', (0., 1)), ('rMBE', (-0.5, 0.5)), ('Interval Score', (0., 4.))]):\n",
    "    for i, model in enumerate(models):\n",
    "        x = metrics_df[(metrics_df['model'] == model) & (metrics_df['horizon'] == HORIZON)][metric].replace([np.inf, -np.inf], np.nan).dropna().values\n",
    "        x_d = np.linspace(-1,4, 2000)\n",
    "        \n",
    "        \n",
    "        kde = KernelDensity(bandwidth=0.03, kernel='gaussian')\n",
    "        kde.fit(x[:, None])\n",
    "        logprob = kde.score_samples(x_d[:, None])\n",
    "        y_d = np.exp(logprob)\n",
    "        if metric == 'NSE':\n",
    "            y_d *= 2\n",
    "        elif metric == 'Interval Score':\n",
    "            y_d *= 4\n",
    "            \n",
    "        if j == 0 and i == 5:\n",
    "            ax[i, j].set_ylabel(f'horizon = {HORIZON}w')\n",
    "        \n",
    "        if HORIZON == 8:\n",
    "            ax[i, j].set_ylim(ylim)\n",
    "        # plotting the distribution\n",
    "        ax[i, j].plot(x_d, y_d, color=\"#f0f0f0\", lw=1)\n",
    "        ax[i, j].fill_between(x_d, y_d, alpha=1, color=colors[i])\n",
    "              \n",
    "        # setting uniform x and y lims\n",
    "        ax[i, j].set_xlim(_range)\n",
    "        #ax[i, j].set_ylim(0, 8)\n",
    "\n",
    "        # make background transparent\n",
    "        rect = ax[i, j].patch\n",
    "        rect.set_alpha(0)\n",
    "\n",
    "        # remove borders, axis ticks, and labels\n",
    "        ax[i, j].set_yticklabels([])\n",
    "        ax[i, j].grid(False)\n",
    "        \n",
    "        if i == 5:\n",
    "            if HORIZON == 8:\n",
    "                ax[i, j].set_xlabel(metric)\n",
    "        else:\n",
    "            ax[i, j].set_xticklabels([])\n",
    "\n",
    "        spines = [\"top\",\"right\",\"left\",\"bottom\"]\n",
    "        for s in spines:\n",
    "            ax[i, j].spines[s].set_visible(False)\n",
    "    \n",
    "    #if metric != 'rMBE':\n",
    "    #    ax[6, j].set_ylim(0, 1)\n",
    "    #    rect = ax[6, j].patch\n",
    "    #    rect.set_alpha(0)\n",
    "    #    _df = metrics_df[metrics_df['horizon'] == HORIZON].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    #    sns.ecdfplot(data=_df, x=\"NSE\", palette=colors, hue='model', ax=ax[6, j], hue_order=['nhits', 'tft', 'nhits_subset', 'tft_subset', 'tft_local_interpolation', 'tft_global_interpolation'], legend=False)\n",
    "    #    ax[6, j].set_xlim(_range)\n",
    "\n",
    "plt.subplots_adjust(hspace=-.85)\n",
    "ylim = ax[0,0].get_ylim()\n",
    "legend_elements = [Patch(facecolor=colors[i], edgecolor=None, label=model) for i, model in enumerate(['N-HiTS', 'N-HiTS (subset)', 'TFT', 'TFT (subset)', 'TFT local interpolation', 'TFT global interpolation'])]\n",
    "if HORIZON == 1:\n",
    "    fig_04.legend(handles=legend_elements,mode = \"expand\", ncols=6, bbox_to_anchor=(0.1, 0.9, 0.78, 0.01))\n",
    "fig_04.savefig(os.path.join(FIGURES_PATH, 'fig04a.pdf'), format='pdf', dpi=300.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 05: Forecast Error by Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "MODEL_MAP = {\n",
    "    'nhits': 'N-HiTS',\n",
    "    'tft': 'TFT',\n",
    "}\n",
    "METRIC = 'NSE'\n",
    "HORIZON = 1\n",
    "\n",
    "fig_05, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "\n",
    "for i, model in enumerate(['nhits', 'tft'], start=1):\n",
    "    _df = (\n",
    "        metrics_df[(metrics_df['model'] == model) & (metrics_df['horizon'] == HORIZON)]\n",
    "        .merge(\n",
    "            static_df[['proj_id', 'lat', 'lon']], on='proj_id', how='left'\n",
    "        )\n",
    "    )\n",
    "    plot_germany(ax[i])\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        _df, geometry=gpd.points_from_xy(_df['lon'], _df['lat']))\n",
    "\n",
    "    gdf.plot(column=f'{METRIC}', ax=ax[i], legend=i==2, markersize=2, cmap='plasma', aspect=1.5, vmin=0., vmax=1., legend_kwds={'label': 'NSE'})\n",
    "    \n",
    "    ax[i].set(\n",
    "        xlabel='longitude',\n",
    "        title=f'{MODEL_MAP[model]}'\n",
    "    )\n",
    "leg = ax[2].get_legend()\n",
    "ax[1].set_ylabel('latitude')\n",
    "\n",
    "img = np.asarray(Image.open(os.path.join(FIGURES_PATH, 'germany_topo.png')))\n",
    "ax[0].imshow(img, aspect=1.)\n",
    "ax[0].set_title('topography')\n",
    "ax[0].grid(visible=False)\n",
    "ax[0].axis('off')\n",
    "\n",
    "\n",
    "fig_05.subplots_adjust(wspace=.05)\n",
    "fig_05.savefig(os.path.join(FIGURES_PATH, 'fig05.pdf'), format='pdf', dpi=300.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 06: Examplary Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wells = pd.read_feather(os.path.join(BASE_PATH, 'results', 'predictions', 'tft_local_interpolation_test_set.feather'))\n",
    "\n",
    "MODELS = ['nhits', 'tft', 'tft_local_interpolation', 'tft_global_interpolation']\n",
    "\n",
    "forecasts = []\n",
    "for model_name in MODELS:\n",
    "    _df = pd.read_feather(os.path.join(BASE_PATH, 'results', 'predictions', f'{model_name}_predictions.feather'))\n",
    "    _df = _df[_df['proj_id'].isin(test_wells['proj_id'].unique())]\n",
    "    _df['model'] = model_name\n",
    "    forecasts.append(_df)\n",
    "forecasts_df = pd.concat(forecasts, sort=True).reset_index(drop=True)\n",
    "\n",
    "forecasts_df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "MODEL_MAP = {\n",
    "    'nhits': 'N-HiTS',\n",
    "    'tft': 'TFT',\n",
    "    'tft_local_interpolation': 'Local\\;Interpolation\\;(TFT)',\n",
    "    'tft_global_interpolation': 'Global\\;Interpolation\\;(TFT)',\n",
    "}\n",
    "\n",
    "PROJ_IDS = ['BW_274-162-3', 'NW_21180301', 'TH_4729230702']\n",
    "subfigures = 'abc'\n",
    "ys = [.35, .37, .5]\n",
    "heights = [6.5, 6., 6.]\n",
    "\n",
    "for proj_id, sub, y_, height in zip(PROJ_IDS, subfigures, ys, heights):\n",
    "\n",
    "    fig, ax = plt.subplots(2, 4, figsize=(22, height), sharex='all', sharey='row')\n",
    "\n",
    "    for c, horizon in enumerate([1, 8]):\n",
    "        forecasts = forecasts_df[(forecasts_df['proj_id'] == proj_id) & (forecasts_df['horizon'] == horizon)]\n",
    "        metrics = metrics_df[(metrics_df['proj_id'] == proj_id) & (metrics_df['horizon'] == horizon)]\n",
    "\n",
    "        for idx, (model, sub_group) in enumerate(forecasts.groupby('model')):\n",
    "            _df = sub_group.set_index('time').sort_index().dropna()\n",
    "            _df[['gwl', 'forecast']].plot(ax=ax[c, idx])\n",
    "            ax[c][idx].fill_between(_df.index.values, _df['forecast_q10'], _df['forecast_q90'], color='orange', alpha=.33)\n",
    "            ax[c][idx].legend().set_visible(False)\n",
    "            _m = metrics[metrics['model'] == model].iloc[0]\n",
    "            title = f\"NSE: {_m['NSE']:.2f}    nRMSE: {_m['nRMSE']:.2f}\\nrMBE: {_m['rMBE']:.2f}    rIS: {_m['Interval Score']:.2f}\"\n",
    "            if sub == 'a' and c == 0:\n",
    "                title = r'$\\bf{' + f'{MODEL_MAP[model]}' + '}$\\n\\n' + title\n",
    "            ax[c][idx].set_title(title, loc='left')\n",
    "            ax[c][0].set_ylabel(f'\\n' + r'$\\bf{horizon = ' + f'{horizon}' + 'w}$\\n\\n\\ngwl [m (asl)]')\n",
    "\n",
    "            if sub != 'c':\n",
    "                ax[c][idx].xaxis.set_tick_params(labelbottom=False)\n",
    "                ax[c][idx].xaxis.set_tick_params(which='minor', labelbottom=False)\n",
    "                ax[c][idx].set_xlabel(None)\n",
    "            ax[c][idx].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "    fig.align_labels()\n",
    "    fig.subplots_adjust(hspace=0.35, top=0.72, bottom=0.05)\n",
    "    plt.annotate(f\"({sub})\\nwell id: {proj_id}\", (0.015, y_), xycoords='figure fraction', rotation=90, va='center', ha='center', weight='bold')\n",
    "    if sub == 'a':\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='#1f77b4', lw=2, label='observed groundwater level'),\n",
    "            Line2D([0], [0], color='orange',  lw=2, label='predicted groundwater level'),\n",
    "            Patch(facecolor='orange', alpha=0.33, edgecolor=None, label='80% confidence interval'),\n",
    "        ]\n",
    "        fig.legend(handles=legend_elements, mode = \"expand\", ncols=3, bbox_to_anchor=(0.12, 0.99, 0.78, 0.01))\n",
    "    fig.savefig(os.path.join(FIGURES_PATH, f'fig06{sub}.pdf'), format='pdf', dpi=300.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 07: Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import kpss\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "TRAIN_PERIOD = (pd.Timestamp(1990, 1, 1), pd.Timestamp(2012, 1, 1))\n",
    "TEST_PERIOD = (pd.Timestamp(2012, 1, 1), pd.Timestamp(2016, 1, 1))\n",
    "\n",
    "_gwl_df = gwl_df.reset_index()\n",
    "train_samples = _gwl_df[_gwl_df['time'].between(*TRAIN_PERIOD)]['proj_id'].value_counts()\n",
    "gwl_stats = _gwl_df.groupby('proj_id')['gwl'].agg(['mean', 'std'])\n",
    "neighbor_stats = pd.read_feather(os.path.join(BASE_PATH, 'results', 'predictions', 'tft_local_interpolation_test_df_stats.feather'))\n",
    "ref_well_stats = pd.read_feather(os.path.join(BASE_PATH, 'results', 'predictions', 'tft_global_interpolation_test_df_stats.feather'))\n",
    "test_samples = _gwl_df[_gwl_df['time'].between(*TEST_PERIOD) & (_gwl_df['proj_id'].isin(metrics_df['proj_id'].unique()))]\n",
    "kpss_list = []\n",
    "seasonality_list = []\n",
    "for proj_id, group in test_samples.groupby('proj_id'):\n",
    "    y = group['gwl'].dropna().values\n",
    "    if len(group) >= 156:\n",
    "        try:\n",
    "            res = kpss(y)[0]\n",
    "            kpss_list.append((proj_id, res))\n",
    "        except:\n",
    "            pass\n",
    "        decomp = seasonal_decompose(y, period=52, two_sided=False)\n",
    "        seasonality_list.append((proj_id, np.std(decomp.seasonal[52:])/np.std(decomp.resid[52:])))\n",
    "kpss_df = pd.DataFrame(kpss_list, columns=['proj_id', 'stationarity'])\n",
    "seas_df = pd.DataFrame(seasonality_list, columns=['proj_id', 'seasonality'])\n",
    "\n",
    "_df = metrics_df[(metrics_df['horizon'] == 1) & (~metrics_df['model'].isin(['nhits_subset', 'tft_subset']))]\n",
    "_df = _df.merge(static_df[['proj_id', 'elevation', 'mohplp_1', 'mohplp_6']], how='left', on='proj_id')\n",
    "_df = _df.merge(train_samples.rename('train_count'), left_on='proj_id', right_index=True, how='left')\n",
    "_df = _df.merge(gwl_stats, left_on='proj_id', right_index=True, how='left')\n",
    "_df['gwl_bgl'] = _df['elevation'] - _df['mean']\n",
    "_df = _df.merge(neighbor_stats, how='left', on='proj_id')\n",
    "_df = _df.merge(ref_well_stats, how='left', on='proj_id')\n",
    "_df = _df.merge(kpss_df, how='left', on='proj_id')\n",
    "_df = _df.merge(seas_df, how='left', on='proj_id')\n",
    "_df = _df[['proj_id', 'horizon', 'NSE', 'nRMSE', 'rMBE', 'Interval Score', 'model', 'std', 'stationarity', 'seasonality', 'gwl_bgl', 'elevation', 'mohplp_1', 'mohplp_6', 'train_count', 'min_ref_dist', 'mean_neighbor_dist', 'hyraum_homogenity']]\n",
    "_df = _df.rename(columns={'mohplp_1': 'lateral position (I)', 'mohplp_6': 'lateral position (VI)',\n",
    "                          'std': 'groundwater level variance', 'gwl_bgl': 'groundwater level depth', \n",
    "                          'hyraum_homogenity': 'hydrogeologic homogenity', \n",
    "                          'mean_neighbor_dist': 'average neighbor distance',\n",
    "                          'min_ref_dist': 'minimum distance to reference well',\n",
    "                          'train_count': 'training samples'})\n",
    "\n",
    "\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colormaps\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "cmap = colormaps['coolwarm']\n",
    "norm = Normalize(vmin=-0.25, vmax=0.25)\n",
    "\n",
    "METRICS = {'NSE', 'Interval Score', 'nRMSE', 'rMBE'}\n",
    "MODEL_MAP = {\n",
    "    'nhits': 'N-HiTS',\n",
    "    'tft': 'TFT',\n",
    "    'tft_local_interpolation': 'Local Interpolation (TFT)',\n",
    "    'tft_global_interpolation': 'Global Interpolation (TFT)',\n",
    "}\n",
    "\n",
    "fig_07, ax = plt.subplots(1, 4, figsize=(22, 6), sharey='row', sharex='all')\n",
    "\n",
    "for i, metric in enumerate(['NSE']):#, 'nRMSE', 'Interval Score']):\n",
    "    corr = _df.drop(columns=['horizon'] + list(METRICS.difference({metric}))).groupby('model').corr(method='pearson')[metric]\n",
    "    for j, (model, group) in enumerate(corr.groupby(axis=0, level=0)):\n",
    "        g = group.droplevel(0)\n",
    "        del g[metric]\n",
    "        if model in ['nhits', 'tft']:\n",
    "            g['minimum distance to reference well'] = np.nan\n",
    "            g['hydrogeologic homogenity'] = np.nan\n",
    "            g['average neighbor distance'] = np.nan\n",
    "        else:\n",
    "            g['training samples'] = np.nan\n",
    "            if model == 'tft_local_interpolation':\n",
    "                g['minimum distance to reference well'] = np.nan\n",
    "            else:\n",
    "                g['average neighbor distance'] = np.nan\n",
    "                g['hydrogeologic homogenity'] = np.nan\n",
    "        ax[j].barh(g[::-1].index, g[::-1].values, color=[cmap(norm(v)) for v in g[::-1]], height=0.2)\n",
    "        ax[j].scatter(g[::-1].values, g[::-1].index, color=[cmap(norm(v)) for v in g[::-1]], s=300)\n",
    "        ax[j].set_xlim((-0.4, 0.4))\n",
    "        ax[j].set_title(MODEL_MAP[model])\n",
    "    \n",
    "fig_07.align_labels()\n",
    "fig_07.subplots_adjust(wspace=0.14)\n",
    "fig_07.savefig(os.path.join(FIGURES_PATH, 'fig07.pdf'), format='pdf', dpi=300.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colormaps\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "cmap = colormaps['coolwarm']\n",
    "norm = Normalize(vmin=-0.25, vmax=0.25)\n",
    "\n",
    "METRICS = {'NSE', 'Interval Score', 'nRMSE', 'rMBE'}\n",
    "MODEL_MAP = {\n",
    "    'nhits': 'N-HiTS',\n",
    "    'tft': 'TFT',\n",
    "    'tft_local_interpolation': 'Local Interpolation (TFT)',\n",
    "    'tft_global_interpolation': 'Global Interpolation (TFT)',\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(4, 3, figsize=(22, 18), sharey='row', sharex='all')\n",
    "\n",
    "for i, metric in enumerate(['NSE', 'nRMSE', 'Interval Score']):\n",
    "    corr = _df.drop(columns=['horizon'] + list(METRICS.difference({metric}))).groupby('model').corr(method='pearson')[metric]\n",
    "    for j, (model, group) in enumerate(corr.groupby(axis=0, level=0)):\n",
    "        g = group.droplevel(0)\n",
    "        del g[metric]\n",
    "        if model in ['nhits', 'tft']:\n",
    "            del g['minimum distance to reference well']\n",
    "            del g['hydrogeologic homogenity']\n",
    "            del g['average neighbor distance']\n",
    "        else:\n",
    "            del g['training samples']\n",
    "            if model == 'tft_local_interpolation':\n",
    "                del g['minimum distance to reference well']\n",
    "            else:\n",
    "                del g['average neighbor distance']\n",
    "                del g['hydrogeologic homogenity']\n",
    "        if j == 0:\n",
    "            title = metric\n",
    "        else:\n",
    "            title = None\n",
    "        if i == 0:\n",
    "            ylabel = MODEL_MAP[model]\n",
    "        else:\n",
    "            ylabel = None\n",
    "            \n",
    "        ax[j, i].barh(g[::-1].index, g[::-1].values, color=[cmap(norm(v)) for v in g[::-1]], height=0.2)\n",
    "        ax[j, i].scatter(g[::-1].values, g[::-1].index, color=[cmap(norm(v)) for v in g[::-1]], s=300)\n",
    "        ax[j, i].set_xlim((-0.5, 0.5))\n",
    "        ax[j, i].set_title(title)\n",
    "        ax[j, i].set_ylabel(ylabel)\n",
    "        #g[::-1].plot.barh(ax=ax[j, i], title=title, ylabel=ylabel, color=[cmap(norm(v)) for v in g[::-1]])\n",
    "        \n",
    "    \n",
    "fig.align_labels()\n",
    "fig.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "fig.savefig(os.path.join(FIGURES_PATH, 'supplement_error_correlation.pdf'), format='pdf', dpi=300.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 08: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "N_NEIGHBORS = 6\n",
    "N_REF_WELLS = 100\n",
    "STATICS = {\n",
    "    'gw_recharge': 'groundwater recharge rate',\n",
    "    'encoder_length': 'encoder length',\n",
    "    'gwl_center': 'groundwater level mean',\n",
    "    'gwl_scale': 'groundwater level variance',\n",
    "    'lon': 'longitude',\n",
    "    'lat': 'latitude',\n",
    "    'elevation': 'elevation',\n",
    "    'cavity_type': 'cavity type',\n",
    "    'permeability': 'permeability',\n",
    "    'rock_type': 'rock type',\n",
    "    'geochemical_rock_type': 'geochemical rock type',\n",
    "    'land_cover': 'land cover',\n",
    "    'percolation': 'percolation rate',\n",
    "    'percolation_n': 'percolation rate*',\n",
    "    'elevation_n': 'elevation*',\n",
    "    'lat_n': 'latitude*',\n",
    "    'lon_n': 'longitude*',\n",
    "    'gw_recharge_n': 'groundwater recharge rate*',\n",
    "    'g_rock_type': 'rock type',\n",
    "    'g_permeability': 'permeability',\n",
    "    'g_geochemical_rock_type': 'geochemical rock type',\n",
    "    'g_land_cover': 'land cover',\n",
    "    'g_cavity_type': 'cavity type'\n",
    "}\n",
    "\n",
    "TEMPORALS = {\n",
    "    'precipitation': 'precipitation',\n",
    "    'humidity': 'humidity',\n",
    "    'temperature': 'temperature',\n",
    "    'gwl': 'groundwater lev.',\n",
    "    'day': 'day of the year',\n",
    "    'lai': 'leaf area index',\n",
    "    'ref_gwl': 'groundwater lev.*',\n",
    "    'gwl_n': 'groundwater lev.*',\n",
    "    'precipitation_n': 'precipitation*',\n",
    "    'humidity_n': 'humidity*',\n",
    "    'temperature_n': 'temperature*',\n",
    "    'lai_n': 'leaf area index*',\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "fig_08, ax = plt.subplots(1, 3, figsize=(24, 12), sharex='all') \n",
    "\n",
    "p = palette = sns.color_palette(\"colorblind\")\n",
    "colors = [p[0], p[2], p[3]]\n",
    "\n",
    "## TFT\n",
    "with open(os.path.join(BASE_PATH, 'results', 'interpretation', 'tft_variable_importance.json')) as f:\n",
    "    tft_interpretation = json.load(f)\n",
    "    \n",
    "tft_interpretation['encoder_variables']['day'] = tft_interpretation['encoder_variables']['day_sin'] + tft_interpretation['encoder_variables']['day_sin']\n",
    "tft_interpretation['decoder_variables']['day'] = tft_interpretation['decoder_variables']['day_sin'] + tft_interpretation['decoder_variables']['day_sin']\n",
    "del tft_interpretation['encoder_variables']['day_sin']\n",
    "del tft_interpretation['encoder_variables']['day_cos']\n",
    "del tft_interpretation['decoder_variables']['day_sin']\n",
    "del tft_interpretation['decoder_variables']['day_cos']\n",
    "\n",
    "tft_interpretation['static_variables'] = dict(zip([STATICS[k] for k in tft_interpretation['static_variables'].keys()], list(tft_interpretation['static_variables'].values())))\n",
    "tft_interpretation['encoder_variables'] = dict(zip([TEMPORALS[k] for k in tft_interpretation['encoder_variables'].keys()], list(tft_interpretation['encoder_variables'].values())))\n",
    "tft_interpretation['decoder_variables'] = dict(zip([TEMPORALS[k] for k in tft_interpretation['decoder_variables'].keys()], list(tft_interpretation['decoder_variables'].values())))\n",
    "\n",
    "## Local interpolation (TFT)\n",
    "with open(os.path.join(BASE_PATH, 'results', 'interpretation', 'tft_local_interpolation_variable_importance.json')) as f:\n",
    "    tft_loc_intp_interpretation = json.load(f)\n",
    "    \n",
    "tft_loc_intp_interpretation['encoder_variables']['day'] = tft_loc_intp_interpretation['encoder_variables']['day_sin'] + tft_loc_intp_interpretation['encoder_variables']['day_sin']\n",
    "tft_loc_intp_interpretation['decoder_variables']['day'] = tft_loc_intp_interpretation['decoder_variables']['day_sin'] + tft_loc_intp_interpretation['decoder_variables']['day_sin']\n",
    "del tft_loc_intp_interpretation['encoder_variables']['day_sin']\n",
    "del tft_loc_intp_interpretation['encoder_variables']['day_cos']\n",
    "del tft_loc_intp_interpretation['decoder_variables']['day_sin']\n",
    "del tft_loc_intp_interpretation['decoder_variables']['day_cos']\n",
    "\n",
    "for var in ['elevation', 'lat', 'lon', 'gw_recharge', 'percolation']:\n",
    "    tft_loc_intp_interpretation['static_variables'][f'{var}_n'] = np.sum([tft_loc_intp_interpretation['static_variables'][f'{var}_n{i}'] for i in range(N_NEIGHBORS)])\n",
    "    for i in range(N_NEIGHBORS):\n",
    "        del tft_loc_intp_interpretation['static_variables'][f'{var}_n{i}']\n",
    "    \n",
    "tft_loc_intp_interpretation['static_variables'] = dict(zip([STATICS[k] for k in tft_loc_intp_interpretation['static_variables'].keys()], list(tft_loc_intp_interpretation['static_variables'].values())))\n",
    "\n",
    "for var in ['humidity', 'precipitation', 'lai', 'temperature', 'gwl']:\n",
    "    tft_loc_intp_interpretation['encoder_variables'][f'{var}_n'] = np.sum([tft_loc_intp_interpretation['encoder_variables'][f'{var}_n{i}'] for i in range(N_NEIGHBORS)])\n",
    "    for i in range(N_NEIGHBORS):\n",
    "        del tft_loc_intp_interpretation['encoder_variables'][f'{var}_n{i}'] \n",
    "\n",
    "tft_loc_intp_interpretation['encoder_variables'] = dict(zip([TEMPORALS[k] for k in tft_loc_intp_interpretation['encoder_variables'].keys()], list(tft_loc_intp_interpretation['encoder_variables'].values())))\n",
    "\n",
    "tft_loc_intp_interpretation['decoder_variables'] = dict(zip([TEMPORALS[k] for k in tft_loc_intp_interpretation['decoder_variables'].keys()], list(tft_loc_intp_interpretation['decoder_variables'].values())))\n",
    "\n",
    "## Global interpolation (TFT)\n",
    "with open(os.path.join(BASE_PATH, 'results', 'interpretation', 'tft_global_interpolation_variable_importance.json')) as f:\n",
    "    tft_glob_intp_interpretation = json.load(f)\n",
    "\n",
    "tft_glob_intp_interpretation['encoder_variables']['day'] = tft_glob_intp_interpretation['encoder_variables']['day_sin'] + tft_glob_intp_interpretation['encoder_variables']['day_sin']\n",
    "tft_glob_intp_interpretation['decoder_variables']['day'] = tft_glob_intp_interpretation['decoder_variables']['day_sin'] + tft_glob_intp_interpretation['decoder_variables']['day_sin']\n",
    "del tft_glob_intp_interpretation['encoder_variables']['day_sin']\n",
    "del tft_glob_intp_interpretation['encoder_variables']['day_cos']\n",
    "del tft_glob_intp_interpretation['decoder_variables']['day_sin']\n",
    "del tft_glob_intp_interpretation['decoder_variables']['day_cos']\n",
    "\n",
    "tft_glob_intp_interpretation['static_variables'] = dict(zip([STATICS[k] for k in tft_glob_intp_interpretation['static_variables'].keys()], list(tft_glob_intp_interpretation['static_variables'].values())))                                                                                                                                                  \n",
    "\n",
    "tft_glob_intp_interpretation['encoder_variables']['ref_gwl'] = np.sum([tft_glob_intp_interpretation['encoder_variables'][f'ref_well_{i}'] for i in range(N_REF_WELLS)])\n",
    "for i in range(N_REF_WELLS):\n",
    "    del tft_glob_intp_interpretation['encoder_variables'][f'ref_well_{i}'] \n",
    "\n",
    "tft_glob_intp_interpretation['encoder_variables'] = dict(zip([TEMPORALS[k] for k in tft_glob_intp_interpretation['encoder_variables'].keys()], list(tft_glob_intp_interpretation['encoder_variables'].values())))\n",
    "\n",
    "tft_glob_intp_interpretation['decoder_variables'] = dict(zip([TEMPORALS[k] for k in tft_glob_intp_interpretation['decoder_variables'].keys()], list(tft_glob_intp_interpretation['decoder_variables'].values())))                                                                                                                                                  \n",
    "\n",
    "_df1 = pd.Series(tft_interpretation['static_variables']).sort_values(ascending=True).to_frame(name='importance').reset_index()\n",
    "_df1['model'] = 'TFT'\n",
    "_df2 = pd.Series(tft_loc_intp_interpretation['static_variables']).sort_values(ascending=True).to_frame(name='importance').reset_index()\n",
    "_df2['model'] = 'Local Interpolation (TFT)'\n",
    "_df3 = pd.Series(tft_glob_intp_interpretation['static_variables']).sort_values(ascending=True).to_frame(name='importance').reset_index()\n",
    "_df3['model'] = 'Global Interpolation (TFT)'\n",
    "dd = pd.concat([_df1, _df2, _df3]).pivot(columns='index', index='model').droplevel(axis=1, level=0)\n",
    "dd = dd.T\n",
    "dd.index.name = None\n",
    "dd.sort_index(ascending=False, inplace=True)\n",
    "dd.plot.barh(color=colors, ylabel=None, title=\"static features\", ax=ax[0], legend=False, width=0.8)\n",
    "\n",
    "_df1 = pd.Series(tft_interpretation['encoder_variables']).sort_values(ascending=True).to_frame(name='importance').reset_index()\n",
    "_df1['model'] = 'TFT'\n",
    "_df2 = pd.Series(tft_loc_intp_interpretation['encoder_variables']).sort_values(ascending=True).to_frame(name='importance').reset_index()\n",
    "_df2['model'] = 'Local Interpolation (TFT)'\n",
    "_df3 = pd.Series(tft_glob_intp_interpretation['encoder_variables']).sort_values(ascending=True).to_frame(name='importance').reset_index()\n",
    "_df3['model'] = 'Global Interpolation (TFT)'\n",
    "dd = pd.concat([_df1, _df2, _df3]).pivot(columns='index', index='model').droplevel(axis=1, level=0)\n",
    "dd = dd.T\n",
    "dd.index.name = None\n",
    "dd.sort_index(ascending=False, inplace=True)\n",
    "dd.plot.barh(color=colors, ylabel=None, title=\"lag features\", ax=ax[1], legend=False, width=0.45)\n",
    "\n",
    "_df1 = pd.Series(tft_interpretation['decoder_variables']).sort_values(ascending=True).to_frame(name='importance').reset_index()\n",
    "_df1['model'] = 'TFT'\n",
    "_df2 = pd.Series(tft_loc_intp_interpretation['decoder_variables']).sort_values(ascending=True).to_frame(name='importance').reset_index()\n",
    "_df2['model'] = 'Local Interpolation (TFT)'\n",
    "_df3 = pd.Series(tft_glob_intp_interpretation['decoder_variables']).sort_values(ascending=True).to_frame(name='importance').reset_index()\n",
    "_df3['model'] = 'Global Interpolation (TFT)'\n",
    "dd = pd.concat([_df1, _df2, _df3]).pivot(columns='index', index='model').droplevel(axis=1, level=0)\n",
    "dd = dd.T\n",
    "dd.index.name = None\n",
    "dd.sort_index(ascending=False, inplace=True)\n",
    "dd.plot.barh(color=colors, ylabel=None, title=\"lead features\", ax=ax[2], legend=False, width=0.2)\n",
    "\n",
    "legend_elements = [\n",
    "        Patch(facecolor=p[3], edgecolor='white', label='TFT'),\n",
    "        Patch(facecolor=p[2], edgecolor='white', label='Local Interpolation (TFT)'),\n",
    "        Patch(facecolor=p[0], edgecolor='white', label='Global Interpolation (TFT)'),\n",
    "    ]\n",
    "fig_08.legend(handles=legend_elements, mode = \"expand\", ncols=3, bbox_to_anchor=(0.5, 0.95, 0.4, 0.01))\n",
    "fig_08.subplots_adjust(wspace=0.5)\n",
    "\n",
    "fig_08.savefig(os.path.join(FIGURES_PATH, 'fig08.pdf'), format='pdf', dpi=300.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplement Fig: Forecasts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "MODEL_MAP = {\n",
    "    'nhits': 'N-HiTS',\n",
    "    'tft': 'TFT',\n",
    "    'tft_local_interpolation': 'Local Interpolation (TFT)',\n",
    "    'tft_global_interpolation': 'Global Interpolation (TFT)',\n",
    "}\n",
    "\n",
    "\n",
    "grouped = forecasts_df.dropna().groupby('proj_id')\n",
    "for c, (proj_id, group) in enumerate(tqdm(grouped)):\n",
    "    try:\n",
    "        metrics = metrics_df[metrics_df['proj_id'] == proj_id]\n",
    "        fig, ax = plt.subplots(3, 4, figsize=(22, 14), sharex='all', sharey='all')\n",
    "        for idx, (model, sub_group) in enumerate(group.groupby('model')):\n",
    "            sub_group['group'] = sub_group['time'] - (sub_group['horizon'] * pd.offsets.Week(1, weekday=6))\n",
    "            sub_group[sub_group['horizon'] == 1].set_index('time').sort_index()[['gwl']].plot(ax=ax[0][idx], color=['#1f77b4'])\n",
    "            for i, (name, _group) in enumerate(sub_group.groupby('group')):\n",
    "                _group.set_index('time').sort_index()[['forecast']].plot(ax=ax[0][idx], legend=i == 0, color=['#ff7f0e99'])\n",
    "            ax[0][idx].legend().set_visible(False)\n",
    "            ax[0][idx].set_title(f'{MODEL_MAP[model]}')\n",
    "\n",
    "            _df = sub_group[sub_group['horizon'] == 1].set_index('time').sort_index()\n",
    "            _df[['gwl', 'forecast']].plot(ax=ax[1][idx])\n",
    "            ax[1][idx].fill_between(_df.index.values, _df['forecast_q10'], _df['forecast_q90'], color='orange', alpha=.33)\n",
    "            ax[1][idx].legend().set_visible(False)\n",
    "            _m = metrics[(metrics['horizon'] == 1) & (metrics['model'] == model)].iloc[0]\n",
    "            ax[1][idx].set_title(f\"NSE: {_m['NSE']:.2f}    nRMSE: {_m['nRMSE']:.2f}\\nrMBE: {_m['rMBE']:.2f}    rIS: {_m['Interval Score']:.2f}\", loc='left')\n",
    "\n",
    "            _df = sub_group[sub_group['horizon'] == 8].set_index('time').sort_index()\n",
    "            _df[['gwl', 'forecast']].plot(ax=ax[2][idx])\n",
    "            ax[2][idx].fill_between(_df.index.values, _df['forecast_q10'], _df['forecast_q90'], color='orange', alpha=.33)\n",
    "            ax[2][idx].legend().set_visible(False)\n",
    "            _m = metrics[(metrics['horizon'] == 8) & (metrics['model'] == model)].iloc[0]\n",
    "            ax[2][idx].set_title(f\"NSE: {_m['NSE']:.2f}    nRMSE: {_m['nRMSE']:.2f}\\nrMBE: {_m['rMBE']:.2f}    rIS: {_m['Interval Score']:.2f}\", loc='left')\n",
    "\n",
    "            ax[0][0].set_ylabel('all horizons\\n\\n\\ngwl [m (asl)]')\n",
    "            ax[1][0].set_ylabel('horizon = 1w\\n\\n\\ngwl [m (asl)]')\n",
    "            ax[2][0].set_ylabel('horizon = 8w\\n\\n\\ngwl [m (asl)]')\n",
    "\n",
    "        fig.align_labels()\n",
    "        fig.subplots_adjust(hspace=0.35)\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='#1f77b4', lw=2, label='observed groundwater level'),\n",
    "            Line2D([0], [0], color='orange',  lw=2, label='predicted groundwater level'),\n",
    "            Patch(facecolor='orange', alpha=0.33, edgecolor=None, label='80% confidence interval'),\n",
    "        ]\n",
    "        fig.legend(handles=legend_elements, loc='upper left')\n",
    "        fig.suptitle(f\"well id: {proj_id}\")\n",
    "        fig.savefig(os.path.join(FIGURES_PATH, 'forecast_plots', f'fig_{c+1:0>3}.pdf'), format='pdf', dpi=300.0)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Supplement Tab: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MAP_ORDER = {\n",
    "    'nhits': 0,\n",
    "    'tft': 2,\n",
    "    'nhits_subset': 1,\n",
    "    'tft_subset': 3,\n",
    "    'tft_local_interpolation': 4,\n",
    "    'tft_global_interpolation': 5,\n",
    "}\n",
    "\n",
    "MODEL_MAP = {\n",
    "    0: 'N-HiTS',\n",
    "    2: 'TFT',\n",
    "    1: 'N-HiTS (subset)',\n",
    "    3: 'TFT (subset)',\n",
    "    4: 'Local Interpolation (TFT)',\n",
    "    5: 'Global Interpolation (TFT)',\n",
    "}\n",
    "\n",
    "agg_metrics = metrics_df[['horizon', 'model', 'NSE', 'nRMSE', 'rMBE', 'Interval Score']].replace([np.inf, -np.inf, np.nan]).dropna().groupby(['model', 'horizon']).agg(['min', 'mean', 'median', 'max']).round(3)\n",
    "agg_metrics.index = agg_metrics.index.map(lambda a: (MODEL_MAP_ORDER[a[0]], a[1]))\n",
    "agg_metrics.sort_index(inplace=True)\n",
    "agg_metrics.index = agg_metrics.index.map(lambda a: (MODEL_MAP[a[0]], a[1]))\n",
    "agg_metrics.to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplement Fig: Forecast error by geologic attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCK_TYPE_CHANNELS = ['n/a', 'sediment', 'metamorphic', 'magmatic', 'G']\n",
    "CAVITY_TYPE_CHANNELS = ['k.A.', 'porous', 'K/P', 'karst', 'fractured/karst', 'nb', 'G']\n",
    "KF_MAP = {\n",
    "    0: 'n/a',\n",
    "    1: 'high',\n",
    "    2: 'high',\n",
    "    8: 'high',\n",
    "    3: 'medium',\n",
    "    4: 'medium',\n",
    "    9: 'medium',\n",
    "    12: 'medium',\n",
    "    5: 'low',\n",
    "    6: 'low',\n",
    "    7: 'low',\n",
    "    10: 'low',\n",
    "    11: 'n/a',\n",
    "    99: 'n/a',\n",
    "}\n",
    "p = palette = sns.color_palette(\"colorblind\")\n",
    "colors = [p[4], p[3]]\n",
    "metric = 'NSE'\n",
    "xlim = (0., 1.)\n",
    "model_dict = {'tft': 'TFT', 'nhits': 'N-HiTS'}\n",
    "\n",
    "_df = metrics_df[(metrics_df['horizon'] == 1) & (metrics_df['model'].isin(['tft', 'nhits']))][['proj_id', 'model', metric]].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "_df['model'] = _df['model'].map(model_dict)\n",
    "_df =_df.merge(static_df, on=['proj_id'], how='left')[['proj_id', metric, 'model', 'rock_type', 'cavity_type', 'permeability']]\n",
    "_df['rock_type'] = _df['rock_type'].apply(lambda x: ROCK_TYPE_CHANNELS[x])\n",
    "_df['cavity_type'] = _df['cavity_type'].apply(lambda x: CAVITY_TYPE_CHANNELS[x])\n",
    "_df['permeability'] = _df['permeability'].apply(lambda x: KF_MAP[x])\n",
    "\n",
    "fig_05, ax = plt.subplots(2, 2, figsize=(12, 8), sharex='col', sharey='row', gridspec_kw={'width_ratios':[1.,1], 'height_ratios': [1., 1.,]})\n",
    "\n",
    "counts = _df[(_df['model'] == 'TFT') & (_df['rock_type'].isin(['sediment', 'magmatic', 'metamorphic']))].groupby('rock_type').count()['proj_id'].reset_index()\n",
    "dd = pd.melt(_df[_df['rock_type'].isin(['sediment', 'magmatic', 'metamorphic'])], id_vars=['rock_type', 'model'], value_vars=[metric], var_name=metric)\n",
    "#sns.boxplot(y='rock_type', x='value', data=dd, orient=\"h\", ax=ax[0][0], order=['sediment', 'pyrogenic', 'metamorphic'])\n",
    "dd['model'] = dd['model'].astype('category')\n",
    "dd['rock_type'] = dd['rock_type'].astype('str')\n",
    "sns.violinplot(data=dd, x=\"value\", y=\"rock_type\", hue=\"model\", split=True, inner=None, ax=ax[0][0], order=['sediment', 'magmatic', 'metamorphic'], palette=colors, bw=0.5)\n",
    "sns.barplot(data=counts, x=\"proj_id\", y=\"rock_type\", orient='h', ax=ax[0][1], order=['sediment', 'magmatic', 'metamorphic'], palette='colorblind')\n",
    "ax[0][0].set(xlim=xlim)\n",
    "ax[0][0].set_ylabel('(a)\\nrock type')\n",
    "ax[0][0].legend(loc='upper left')\n",
    "ax[0][1].set_ylabel(None)\n",
    "ax[0][1].set_xlabel(None)\n",
    "ax[0][0].set_xlabel(None)\n",
    "\n",
    "#counts = _df[(_df['model'] == 'TFT') & (_df['cavity_type'].isin(['porous', 'fractured/karst', 'karst']))].groupby('cavity_type').count()['proj_id'].reset_index()\n",
    "#dd = pd.melt(_df[_df['cavity_type'].isin(['porous', 'fractured/karst', 'karst'])], id_vars=['cavity_type', 'model'], value_vars=[metric], var_name=metric)\n",
    "#sns.boxplot(y='cavity_type', x='value', data=dd, orient=\"h\", ax=ax[1][0], order=['porous', 'fractured/karst', 'karst'])\n",
    "#sns.barplot(data=counts, x=\"proj_id\", y=\"cavity_type\", orient='h', ax=ax[1][1], order=['porous', 'fractured/karst', 'karst'])\n",
    "#dd['model'] = dd['model'].astype('category')\n",
    "#dd['cavity_type'] = dd['cavity_type'].astype('str')\n",
    "#sns.violinplot(data=dd, x=\"value\", y=\"cavity_type\", hue=\"model\", split=True, inner=None, ax=ax[1][0], order=['porous', 'fractured/karst', 'karst'], palette=colors)\n",
    "#ax[1][0].set(xlim=xlim)\n",
    "#ax[1][0].set_ylabel('(b)\\ncavity type')\n",
    "#ax[1][0].legend().set_visible(False)\n",
    "#ax[1][1].set_ylabel(None)\n",
    "#ax[1][1].set_xlabel(None)\n",
    "#ax[1][0].set_xlabel(None)\n",
    "\n",
    "counts = _df[(_df['model'] == 'TFT') & (_df['permeability'].isin(['high', 'medium', 'low']))].groupby('permeability').count()['proj_id'].reset_index()\n",
    "dd = pd.melt(_df[_df['permeability'].isin(['high', 'medium', 'low'])], id_vars=['permeability', 'model'], value_vars=[metric], var_name=metric)\n",
    "#sns.boxplot(y='permeability', x='value', data=dd, orient=\"h\", ax=ax[2][0], order=['high', 'medium', 'low'])\n",
    "sns.barplot(data=counts, x=\"proj_id\", y=\"permeability\", orient='h', ax=ax[1][1], order=['high', 'medium', 'low'], palette='colorblind')\n",
    "dd['model'] = dd['model'].astype('category')\n",
    "dd['permeability'] = dd['permeability'].astype('str')\n",
    "sns.violinplot(data=dd, x=\"value\", y=\"permeability\", hue=\"model\", split=True, inner=None, ax=ax[1][0], order=['high', 'medium', 'low'], palette=colors, bw=0.5)\n",
    "ax[1][0].set(xlim=xlim, xlabel=metric)\n",
    "ax[1][0].set_ylabel('(b)\\npermeability')\n",
    "ax[1][0].legend().set_visible(False)\n",
    "ax[1][1].set_ylabel(None)\n",
    "ax[1][1].set_xlabel(\"wells\")\n",
    "fig_05.align_labels()\n",
    "fig_05.subplots_adjust(wspace=0.09)\n",
    "fig_05.savefig(os.path.join(FIGURES_PATH, 'error_by_geology.pdf'), format='pdf', dpi=300.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplement: Mean Absolute Error per Location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MAP = {\n",
    "    'tft_local_interpolation': 'Local Interpolation (TFT)',\n",
    "    'tft_global_interpolation': 'Global Interpolation (TFT)',\n",
    "}\n",
    "METRIC = 'NSE'\n",
    "HORIZON = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "\n",
    "for i, model in enumerate(['tft_local_interpolation', 'tft_global_interpolation']):\n",
    "    _df = (\n",
    "        forecasts_df[(forecasts_df['model'] == model) & (forecasts_df['horizon'] == HORIZON)]\n",
    "    )\n",
    "    _df['abs_diff'] = (_df['forecast'] - _df['gwl']).abs()\n",
    "    _df = _df.groupby('proj_id')['abs_diff'].mean()\n",
    "    _df = _df.to_frame().merge(\n",
    "            static_df[['proj_id', 'lat', 'lon']], on='proj_id', how='left')\n",
    "    \n",
    "    plot_germany(ax[i])\n",
    "    \n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        _df, geometry=gpd.points_from_xy(_df['lon'], _df['lat']))\n",
    "\n",
    "    gdf.plot(column=f'abs_diff', ax=ax[i], legend=i==1, markersize=8, cmap=sns.color_palette(\"Spectral_r\", as_cmap=True), aspect=1.5, vmin=0., vmax=4., legend_kwds={'label': 'Mean Absolute Error [m]'})\n",
    "    \n",
    "    ax[i].set(\n",
    "        xlabel='longitude',\n",
    "        title=f'{MODEL_MAP[model]}'\n",
    "    )\n",
    "leg = ax[1].get_legend()\n",
    "ax[0].set_ylabel('latitude')\n",
    "fig.subplots_adjust(wspace=.02)\n",
    "fig.savefig(os.path.join(FIGURES_PATH, 'spatial_interpolation_mae.pdf'), format='pdf', dpi=300.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplement: Interpolated Groundwater Level Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.warp import calculate_default_transform\n",
    "\n",
    "src_crs = rasterio.CRS.from_epsg(3034)\n",
    "dst_crs = rasterio.CRS.from_epsg(4326)\n",
    "\n",
    "elevation = np.load(os.path.join(DATA_PATH, 'elevation.npy'))[0]\n",
    "\n",
    "with rasterio.open(os.path.join(RESULTS_PATH, 'gwl_map_2015_01_04-2015_12_27.tif')) as src:\n",
    "    transform, width, height = calculate_default_transform(src_crs, dst_crs, src.width, src.height, *src.bounds, dst_width=src.width, dst_height=src.height)\n",
    "    cols, rows = np.meshgrid(np.arange(src.width), np.arange(src.height))\n",
    "    lons, lats = rasterio.transform.xy(transform, rows, cols)\n",
    "    lons, lats = lons[0], np.stack(lats)[:, 0]\n",
    "    map_data = src.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(25, 6), sharex='all', sharey='all', gridspec_kw={'width_ratios': [1, 1, 1, 1.25]})\n",
    "\n",
    "date_range = pd.date_range('2015-01-04', '2015-12-27', freq='W-SUN')\n",
    "indices = [0, 52//4, 52//2, (52//4)*3]\n",
    "\n",
    "for idx, i in enumerate(indices):\n",
    "    _ax = ax[idx]\n",
    "    data = np.clip(map_data[i] - elevation, a_max=0, a_min=None)\n",
    "    p = _ax.imshow(data, extent=[np.min(lons), np.max(lons), np.min(lats), np.max(lats)], aspect=1.5)\n",
    "    _ax.set_title(date_range[i].date())\n",
    "    _ax.set_xlabel('longitude')\n",
    "    _ax.set_ylabel('latitude')\n",
    "    if idx == 3:\n",
    "        plt.colorbar(p, ax=_ax, label='meter (bgl)')\n",
    "\n",
    "fig.savefig(os.path.join(FIGURES_PATH, 'groundwater_map_bgl.pdf'), format='pdf', dpi=300.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
